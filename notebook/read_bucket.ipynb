{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azure-storage-blob\n",
    "#!pip install xml-python\n",
    "#!pip install bs4\n",
    "#!pip install BeautifulSoup\n",
    "#!pip install lxml\n",
    "#!pip install pandas\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "!c:/Users/marco/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Connect to the storage account\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=<your_account_name>;AccountKey=<your_account_key>;EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Get a reference to the raw container and file\n",
    "raw_container_name = \"<your_raw_container_name>\"\n",
    "raw_blob_name = \"<your_raw_blob_name>\"\n",
    "raw_blob_client = blob_service_client.get_blob_client(container=raw_container_name, blob=raw_blob_name)\n",
    "\n",
    "# Download the file contents as a string\n",
    "raw_file_contents = raw_blob_client.download_blob().content_as_text()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading XML Data Danfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import pytz\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÕES GLOBAIS\n",
    "def read_context(json_path: str):\n",
    "    \"\"\"\n",
    "    Read json content in order to get context variables from data process.\n",
    "    Args:\n",
    "        json_path: path from where json file containing project\n",
    "            information is.\n",
    "    \"\"\"\n",
    "\n",
    "    context_file = open(json_path)\n",
    "    context = json.load(context_file)\n",
    "\n",
    "    return context\n",
    "\n",
    "def set_dtypes(df, dtypes):\n",
    "    for column in dtypes:\n",
    "        #print(column)\n",
    "        df[column] = df[column].astype(dtypes[column])\n",
    "    return df\n",
    "\n",
    "def convert_float_to_int(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype(np.int64)\n",
    "    return df\n",
    "\n",
    "def data_load():\n",
    "    brasil_fuso_horario = pytz.timezone(\"America/Sao_Paulo\")\n",
    "    data_atual = datetime.now(brasil_fuso_horario).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return data_atual\n",
    "\n",
    "def cria_data_fonte_e_carga(df,coluna):\n",
    "    df['data_fonte'] = pd.to_datetime(df[coluna], format='%Y-%m-%d %H:%M:%S',errors='ignore').dt.strftime('%Y-%m-%d %H:%M')\n",
    "    df['data_carga']  = data_load()\n",
    "    return df\n",
    "\n",
    "def cria_coluna_year_month_day(df,coluna: str):\n",
    "    df[\"year\"] = df[coluna].str.slice(0,4)\n",
    "    df[\"month\"] = df[coluna].str.slice(5,7)\n",
    "    df[\"day\"] = df[coluna].str.slice(8,10)\n",
    "    return df\n",
    "\n",
    "def connect_storage_account():\n",
    "    context = read_context('context\\transform-info.json')\n",
    "    connect_str = context['transform-info'][0]['connect_string']\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    return blob_service_client\n",
    "\n",
    "def get_container_xml_raw(container : str, blob : str):\n",
    "    raw_container_client = blob_service_client.get_container_client(container)\n",
    "\n",
    "    # Especificando o caminho do arquivo CSV no seu bucket\n",
    "    blob_client = raw_container_client.get_blob_client(blob)\n",
    "\n",
    "    # Lendo o arquivo CSV em um objeto pandas DataFrame\n",
    "    #csv_data = blob_client.download_blob().content_as_text()\n",
    "    xml = blob_client.download_blob()\n",
    "    return xml\n",
    "\n",
    "def create_data_frame_danfe(xml):\n",
    "    # define o namespace\n",
    "    namespace = {'nfe': 'http://www.portalfiscal.inf.br/nfe'}\n",
    "\n",
    "    # carrega o arquivo XML\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # extrai os dados das tags\n",
    "    cUF = root.find('.//nfe:cUF', namespace).text\n",
    "    cNF = root.find('.//nfe:cNF', namespace).text\n",
    "    numero_nf = root.find('.//nfe:nNF', namespace).text\n",
    "    data_emissao = root.find('.//nfe:dhEmi', namespace).text\n",
    "    natOp = root.find('.//nfe:natOp', namespace).text\n",
    "    CNPJ_emit = root.find('.//nfe:CNPJ', namespace).text\n",
    "    nome_emitente = root.find('.//nfe:emit/nfe:xNome', namespace).text\n",
    "    logadouro_emitente = root.find('.//nfe:emit/nfe:enderEmit/nfe:xLgr', namespace).text\n",
    "    numero_emitente = root.find('.//nfe:emit/nfe:enderEmit/nfe:nro', namespace).text\n",
    "    bairro_emitente  = root.find('.//nfe:emit/nfe:enderEmit/nfe:xBairro', namespace).text\n",
    "    fone_emitente  = root.find('.//nfe:emit/nfe:enderEmit/nfe:fone', namespace).text\n",
    "    nome_cliente = root.find('.//nfe:dest/nfe:xNome', namespace).text\n",
    "\n",
    "    # cria o DataFrame com as colunas desejadas\n",
    "    df = pd.DataFrame(columns=['codigo_produto', 'descricao_produto', 'ncm', 'valor', 'quantidade','base_calculo_icms','aliquota_icms','valor_icms'])\n",
    "\n",
    "    # itera sobre todas as tags <det> para extrair os dados de cada produto\n",
    "    for det in root.findall('.//nfe:det', namespace):\n",
    "        prod_dict = {\n",
    "            'codigo_produto': det.find('nfe:prod/nfe:cProd', namespace).text,\n",
    "            'descricao_produto': det.find('nfe:prod/nfe:xProd', namespace).text,\n",
    "            'ncm': det.find('nfe:prod/nfe:NCM', namespace).text,\n",
    "            'valor': det.find('nfe:prod/nfe:vProd', namespace).text,\n",
    "            'quantidade': det.find('nfe:prod/nfe:qCom', namespace).text,\n",
    "            'base_calculo_icms' : det.find('nfe:imposto/nfe:ICMS/nfe:ICMS00/nfe:vBC', namespace).text,\n",
    "            'aliquota_icms' : det.find('nfe:imposto/nfe:ICMS/nfe:ICMS00/nfe:pICMS', namespace).text,\n",
    "            'valor_icms' : det.find('nfe:imposto/nfe:ICMS/nfe:ICMS00/nfe:vICMS', namespace).text\n",
    "\n",
    "        }\n",
    "        \n",
    "        # adiciona o dicionário ao DataFrame\n",
    "        df = df.append(prod_dict, ignore_index=True)\n",
    "        df['codigo_uf_emitente'] = cUF\n",
    "        df['codigo_nf'] = cNF\n",
    "        df['numero_nf'] = numero_nf\n",
    "        df['data_emissao'] = data_emissao\n",
    "        df['natureza_operacao'] = natOp\n",
    "        df['cnpj_emitente'] = CNPJ_emit\n",
    "        df['nome_emitente'] = nome_emitente\n",
    "        df['logadouro_emitente'] = logadouro_emitente\n",
    "        df['numero_emitente'] = numero_emitente       \n",
    "        df['bairro_emitente'] = bairro_emitente       \n",
    "        df['fone_emitente'] = fone_emitente         \n",
    "        df['nome_cliente'] = nome_cliente\n",
    "        return df\n",
    "    \n",
    "def save_container_processing_parquet(df,blob_service_client):\n",
    "    # SAve parquet processing .get_blob_client('danfe.parquet')\n",
    "    processing_container_name = blob_service_client.get_container_client(\"processing\")\n",
    "    parquet_blob_client = blob_service_client.get_container_client(processing_container_name).get_blob_client('danfe.parquet')\n",
    "    parquet_blob_data = df.to_parquet(parquet_blob_client, partition_cols=['year', 'month', 'day'], index=False, engine='fastparquet')\n",
    "    parquet_blob_client.upload_blob(parquet_blob_data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_convert_int = ['quantidade','aliquota_icms']\n",
    "data_types_nfe = {\n",
    "      'codigo_produto' : np.int64,\n",
    "      'descricao_produto' : object,                 \n",
    "      'ncm' : object,\n",
    "      'valor' : np.float64,\n",
    "      'quantidade' : np.float64,\n",
    "      'base_calculo_icms': np.float64,\n",
    "      'aliquota_icms' : np.float64,\n",
    "      'valor_icms' : np.float64,\n",
    "      'codigo_uf_emitente' : np.int64,\n",
    "      'codigo_nf' : np.int64,\n",
    "      'numero_nf' : np.int64,\n",
    "      'data_emissao' : np.datetime64,\n",
    "      'natureza_operacao' : object ,\n",
    "      'cnpj_emitente' : object,\n",
    "      'nome_emitente' : object,\n",
    "      'logadouro_emitente' : object,\n",
    "      'numero_emitente' : object,\n",
    "      'bairro_emitente' : object,\n",
    "      'fone_emitente' : object,\n",
    "      'nome_cliente' : object      \n",
    "   }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes Leitura XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('cobase-nfe2.xml', parser = ET.XMLParser(encoding = 'utf-8'))\n",
    "root = ET.parse('cobase-nfe2.xml',).getroot()\n",
    "\n",
    "nsNFE = {'ns': \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "\n",
    "numero_nfe = root.find('ns:NFe/ns:infNFe/ns:ide/ns:cNF',nsNFE).text\n",
    "natOp = root.find('ns:NFe/ns:infNFe/ns:ide/ns:natOp',nsNFE).text\n",
    "chave_nfe = root.find('ns:NFe/ns:infNFe',nsNFE).attrib['Id'][3:]\n",
    "\n",
    "# Dados Emissor\n",
    "emit_cnpj = root.find('ns:NFe/ns:infNFe/ns:emit/ns:CNPJ',nsNFE).text\n",
    "emit_nome = root.find('ns:NFe/ns:infNFe/ns:emit/ns:xNome',nsNFE).text\n",
    "emit_lgr = root.find('ns:NFe/ns:infNFe/ns:emit/ns:enderEmit/ns:xLgr',nsNFE).text\n",
    "emit_nro = root.find('ns:NFe/ns:infNFe/ns:emit/ns:enderEmit/ns:nro',nsNFE).text\n",
    "emit_xBairro = root.find('ns:NFe/ns:infNFe/ns:emit/ns:enderEmit/ns:xBairro',nsNFE).text\n",
    "\n",
    "cProd = root.findall('ns:NFe/ns:infNFe/ns:det/ns:prod/ns:cProd',nsNFE)\n",
    "\n",
    "\n",
    "#print(numero_nfe.text, chave_nfe)\n",
    "\n",
    "dados = {\n",
    "    \"numero_nfe\" : [numero_nfe],\n",
    "    \"natOp\" : [natOp],\n",
    "    \"chave_nfe\" : [chave_nfe],\n",
    "    \"emit_cnpj\":[emit_cnpj],\n",
    "    \"emit_nome\":[emit_nome],\n",
    "    \"emit_lgr\":[emit_lgr],\n",
    "    \"emit_nro\":[emit_nro],\n",
    "    \"emit_xBairro\":[emit_xBairro]\n",
    "}\n",
    "#dados\n",
    "lista = []\n",
    "dic = {}\n",
    "for p in root.iter('nItem'):\n",
    "    #dic['cProd'] = p.find('prod/cProd').text\n",
    "    #lista.append(dic)\n",
    "    print(p.text)\n",
    "#print(lista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = open('cobase-nfe2.xml')\n",
    "nfe = minidom.parse(xml)\n",
    "\n",
    "lista = []\n",
    "produtos = nfe.getElementsByTagName('cProd')\n",
    "xProd = nfe.getElementsByTagName('xProd')\n",
    "vProd = nfe.getElementsByTagName('vProd')\n",
    "\n",
    "for p in produtos:\n",
    "    dic = {}\n",
    "    dic['cod_prod'] = p.firstChild.data    \n",
    "    lista.append(dic)\n",
    "    #print(p.firstChild.data)\n",
    "for xProd in xProd:\n",
    "    dic = {}\n",
    "    dic['xProd'] = xProd.firstChild.data    \n",
    "    lista.append(dic)\n",
    "for vProd in vProd:\n",
    "    dic = {}\n",
    "    dic['vProd'] = vProd.firstChild.data    \n",
    "    lista.append(dic)\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = nfe.getElementsByTagName('cProd')\n",
    "xProd = nfe.getElementsByTagName('xProd')\n",
    "lista = [{'cod_prod': p.firstChild.data} for p in produtos] + [{'xProd': x.firstChild.data} for x in xProd]\n",
    "lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cobase-nfe2.xml') as xml:\n",
    "    nfe = minidom.parse(xml)\n",
    "\n",
    "produtos = nfe.getElementsByTagName('cProd') + \\\n",
    "           nfe.getElementsByTagName('xProd')\n",
    "lista = [{'cod_prod': p.firstChild.data} if p.tagName == 'cProd' else {'xProd': p.firstChild.data} for p in produtos]\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('cobase-nfe2.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "produtos = root.findall('.//det')\n",
    "\n",
    "lista = [{'cod_prod': p.find('prod/cProd').text,\n",
    "          'xProd': p.find('prod/xProd').text,\n",
    "          'vProd': p.find('prod/vProd').text} for p in produtos]\n",
    "lista\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = open('cobase-nfe2.xml')\n",
    "nfe = minidom.parse(xml)\n",
    "\n",
    "lista = []\n",
    "produtos = nfe.getElementsByTagName('det')\n",
    "\n",
    "for produto in produtos:\n",
    "    cod_prod = produto.getElementsByTagName('cProd')[0].firstChild.data\n",
    "    xProd = produto.getElementsByTagName('xProd')[0].firstChild.data\n",
    "    vProd = produto.getElementsByTagName('vProd')[0].firstChild.data\n",
    "    dic = {'cod_prod': cod_prod, 'xProd': xProd, 'vProd': vProd}\n",
    "    lista.append(dic)\n",
    "\n",
    "xml.close()\n",
    "lista\n",
    "\n",
    "\n",
    "#pd.DataFrame(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dados)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "\n",
    "#numero_nfe = root.find()\n",
    "parser = etree.XMLParser(recover=True,encoding='utf-8') #iso-8859-5\n",
    "root = ET.parse('cobase-nfe.xml',parser=parser).getroot()\n",
    "\n",
    "nsNFE = {'ns': \"http://www.portalfiscal.inf.br/nfe\"}\n",
    "numero_nfe = root.find('ns:NFe/ns:infNFe/ns:ide/ns:nNF',nsNFE)\n",
    "chave_nfe = root.find('ns:NFe/ns:infNFe',nsNFE).attrib['Id'][3:]\n",
    "\n",
    "#tree = etree.parse('danfe.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52230353153938018317550020000060871137093993\n"
     ]
    }
   ],
   "source": [
    "#print(numero_nfe.text)\n",
    "#print(chave_nfe.attrib['Id'][3:])\n",
    "print(chave_nfe)\n",
    "#numero_nfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = open('danfe.xml')\n",
    "nfe = minidom.parse(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Carrega o XML\n",
    "tree = ET.parse('cobase-nfe2.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Obtém as informações da nota fiscal\n",
    "cUF = root.find('.//{http://www.portalfiscal.inf.br/nfe}cUF').text\n",
    "cNF = root.find('.//{http://www.portalfiscal.inf.br/nfe}cNF').text\n",
    "natOp = root.find('.//{http://www.portalfiscal.inf.br/nfe}natOp').text\n",
    "CNPJ_emit = root.find('.//{http://www.portalfiscal.inf.br/nfe}emit/{http://www.portalfiscal.inf.br/nfe}CNPJ').text\n",
    "xNome_emit = root.find('.//{http://www.portalfiscal.inf.br/nfe}emit/{http://www.portalfiscal.inf.br/nfe}xNome').text\n",
    "\n",
    "# Cria uma lista com as informações dos produtos\n",
    "produtos = []\n",
    "for det in root.findall('.//{http://www.portalfiscal.inf.br/nfe}det'):\n",
    "    cProd = det.find('{http://www.portalfiscal.inf.br/nfe}prod/{http://www.portalfiscal.inf.br/nfe}cProd').text\n",
    "    xProd = det.find('{http://www.portalfiscal.inf.br/nfe}prod/{http://www.portalfiscal.inf.br/nfe}xProd').text\n",
    "    NCM = det.find('{http://www.portalfiscal.inf.br/nfe}prod/{http://www.portalfiscal.inf.br/nfe}NCM').text\n",
    "    vUnCom = det.find('{http://www.portalfiscal.inf.br/nfe}prod/{http://www.portalfiscal.inf.br/nfe}vUnCom').text\n",
    "    produtos.append({'cProd': cProd, 'xProd': xProd, 'NCM': NCM, 'vUnCom': vUnCom})\n",
    "\n",
    "# Cria o DataFrame pandas\n",
    "df = pd.DataFrame(produtos)\n",
    "df['cUF'] = cUF\n",
    "df['cNF'] = cNF\n",
    "df['natOp'] = natOp\n",
    "df['CNPJ_emit'] = CNPJ_emit\n",
    "df['xNome_emit'] = xNome_emit\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def extract_data_from_xml(xml_string):\n",
    "    root = ET.fromstring(xml_string)\n",
    "\n",
    "    # Extrair informações do cabeçalho\n",
    "    header = root.find('.//{http://www.portalfiscal.inf.br/nfe}ide')\n",
    "    data = {\n",
    "        'cUF': header.find('cUF').text,\n",
    "        'cNF': header.find('cNF').text,\n",
    "        'natOp': header.find('natOp').text,\n",
    "        'CNPJ': header.find('.//{http://www.portalfiscal.inf.br/nfe}CNPJ').text,\n",
    "        'xNome': header.find('.//{http://www.portalfiscal.inf.br/nfe}xNome').text\n",
    "    }\n",
    "\n",
    "    # Extrair informações dos produtos\n",
    "    products = root.iter('{http://www.portalfiscal.inf.br/nfe}det')\n",
    "    for product in products:\n",
    "        data.update({\n",
    "            f\"cProd_{product.get('nItem')}\": product.find('prod/cProd').text,\n",
    "            f\"xProd_{product.get('nItem')}\": product.find('prod/xProd').text,\n",
    "            f\"NCM_{product.get('nItem')}\": product.find('prod/NCM').text,\n",
    "            f\"vUnCom_{product.get('nItem')}\": product.find('prod/vUnCom').text\n",
    "        })\n",
    "\n",
    "    # Criar o DataFrame a partir do dicionário de dados\n",
    "    df = pd.DataFrame.from_dict([data])\n",
    "\n",
    "    return df\n",
    "extract_data_from_xml('cobase-nfe2.xml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código final Transformação Nota fiscal XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'context/transform-info.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39m#save_container_processing_parquet(df,blob_service_client)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 12\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[118], line 2\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m ():\n\u001b[1;32m----> 2\u001b[0m     blob_service_client \u001b[39m=\u001b[39m connect_storage_account()\n\u001b[0;32m      3\u001b[0m     xml \u001b[39m=\u001b[39m get_container_xml_raw(\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcobase-nfe2.xml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     df \u001b[39m=\u001b[39m create_data_frame_danfe(xml)\n",
      "Cell \u001b[1;32mIn[116], line 43\u001b[0m, in \u001b[0;36mconnect_storage_account\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect_storage_account\u001b[39m():\n\u001b[1;32m---> 43\u001b[0m     context \u001b[39m=\u001b[39m read_context(\u001b[39m'\u001b[39;49m\u001b[39mcontext/transform-info.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m     connect_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDefaultEndpointsProtocol=https;AccountName=t10storageaccount;AccountKey=+SRaplCEmzyqKRW+3j0jd79Qo6eganpiz+56yobjx5zAFwMuUk7eQeB9T/WfdutiI4VryBsc0oQm+AStxlYVng==;EndpointSuffix=core.windows.net\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m     blob_service_client \u001b[39m=\u001b[39m BlobServiceClient\u001b[39m.\u001b[39mfrom_connection_string(connect_str)\n",
      "Cell \u001b[1;32mIn[116], line 10\u001b[0m, in \u001b[0;36mread_context\u001b[1;34m(json_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_context\u001b[39m(json_path: \u001b[39mstr\u001b[39m):\n\u001b[0;32m      3\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    Read json content in order to get context variables from data process.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m        json_path: path from where json file containing project\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m            information is.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     context_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(json_path)\n\u001b[0;32m     11\u001b[0m     context \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(context_file)\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m context\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'context/transform-info.json'"
     ]
    }
   ],
   "source": [
    "def main ():\n",
    "    blob_service_client = connect_storage_account()\n",
    "    xml = get_container_xml_raw('raw','cobase-nfe2.xml')\n",
    "    df = create_data_frame_danfe(xml)\n",
    "    df = set_dtypes(df, data_types_nfe)\n",
    "    df = convert_float_to_int(df,columns_convert_int)\n",
    "    df = cria_data_fonte_e_carga(df, 'data_emissao')\n",
    "    df = cria_coluna_year_month_day(df, 'data_fonte')\n",
    "    #save_container_processing_parquet(df,blob_service_client)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['data_fonte'] = pd.to_datetime(df['data_emissao'], format='%Y-%m-%d %H:%M:%S',errors='ignore').dt.strftime('%Y-%m-%d %H:%M')\n",
    "#df['data_carga']  = data_load()\n",
    "df.head()\n",
    "#df.dtypes\n",
    "#df.to_parquet(destination_bucket_name, partition_cols=['YEAR', 'MONTH', 'DAY'],engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "quote_from_bytes() expected bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# SAve parquet processing .get_blob_client('danfe.parquet')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m processing_container_name \u001b[39m=\u001b[39m blob_service_client\u001b[39m.\u001b[39mget_container_client(\u001b[39m\"\u001b[39m\u001b[39mprocessing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m parquet_blob_client \u001b[39m=\u001b[39m blob_service_client\u001b[39m.\u001b[39;49mget_container_client(processing_container_name)\u001b[39m.\u001b[39mget_blob_client(\u001b[39m'\u001b[39m\u001b[39mdanfe.parquet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m parquet_blob_data \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mto_parquet(parquet_blob_client, partition_cols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m], index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m parquet_blob_client\u001b[39m.\u001b[39mupload_blob(parquet_blob_data, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azure\\storage\\blob\\_blob_service_client.py:724\u001b[0m, in \u001b[0;36mBlobServiceClient.get_container_client\u001b[1;34m(self, container)\u001b[0m\n\u001b[0;32m    719\u001b[0m     container_name \u001b[39m=\u001b[39m container\n\u001b[0;32m    720\u001b[0m _pipeline \u001b[39m=\u001b[39m Pipeline(\n\u001b[0;32m    721\u001b[0m     transport\u001b[39m=\u001b[39mTransportWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline\u001b[39m.\u001b[39m_transport), \u001b[39m# pylint: disable = protected-access\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     policies\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline\u001b[39m.\u001b[39m_impl_policies \u001b[39m# pylint: disable = protected-access\u001b[39;00m\n\u001b[0;32m    723\u001b[0m )\n\u001b[1;32m--> 724\u001b[0m \u001b[39mreturn\u001b[39;00m ContainerClient(\n\u001b[0;32m    725\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, container_name\u001b[39m=\u001b[39;49mcontainer_name,\n\u001b[0;32m    726\u001b[0m     credential\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcredential, api_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_version, _configuration\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config,\n\u001b[0;32m    727\u001b[0m     _pipeline\u001b[39m=\u001b[39;49m_pipeline, _location_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_location_mode, _hosts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hosts,\n\u001b[0;32m    728\u001b[0m     require_encryption\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequire_encryption, encryption_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencryption_version,\n\u001b[0;32m    729\u001b[0m     key_encryption_key\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_encryption_key, key_resolver_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_resolver_function)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azure\\storage\\blob\\_container_client.py:162\u001b[0m, in \u001b[0;36mContainerClient.__init__\u001b[1;34m(self, account_url, container_name, credential, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39msuper\u001b[39m(ContainerClient, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(parsed_url, service\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblob\u001b[39m\u001b[39m'\u001b[39m, credential\u001b[39m=\u001b[39mcredential, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api_version \u001b[39m=\u001b[39m get_api_version(kwargs)\n\u001b[1;32m--> 162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_generated_client()\n\u001b[0;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_encryption(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azure\\storage\\blob\\_container_client.py:166\u001b[0m, in \u001b[0;36mContainerClient._build_generated_client\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_generated_client\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 166\u001b[0m     client \u001b[39m=\u001b[39m AzureBlobStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, base_url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl, pipeline\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline)\n\u001b[0;32m    167\u001b[0m     client\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mversion \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api_version \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m client\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azure\\storage\\blob\\_shared\\base_client.py:131\u001b[0m, in \u001b[0;36mStorageAccountHostsMixin.url\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39murl\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The full endpoint URL to this entity, including SAS token if used.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    This could be either the primary endpoint,\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    or the secondary endpoint depending on the current :func:`location_mode`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hosts[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_location_mode])\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azure\\storage\\blob\\_container_client.py:177\u001b[0m, in \u001b[0;36mContainerClient._format_url\u001b[1;34m(self, hostname)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(container_name, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    173\u001b[0m     container_name \u001b[39m=\u001b[39m container_name\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mUTF-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m://\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    175\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheme,\n\u001b[0;32m    176\u001b[0m     hostname,\n\u001b[1;32m--> 177\u001b[0m     quote(container_name),\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_str)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\urllib\\parse.py:839\u001b[0m, in \u001b[0;36mquote\u001b[1;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    838\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mquote() doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support \u001b[39m\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for bytes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 839\u001b[0m \u001b[39mreturn\u001b[39;00m quote_from_bytes(string, safe)\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python38\\lib\\urllib\\parse.py:864\u001b[0m, in \u001b[0;36mquote_from_bytes\u001b[1;34m(bs, safe)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Like quote(), but accepts a bytes object rather than a str, and does\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39mnot perform string-to-bytes encoding.  It always returns an ASCII string.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[39mquote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(bs, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mquote_from_bytes() expected bytes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bs:\n\u001b[0;32m    866\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: quote_from_bytes() expected bytes"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=t10storageaccount;AccountKey=+SRaplCEmzyqKRW+3j0jd79Qo6eganpiz+56yobjx5zAFwMuUk7eQeB9T/WfdutiI4VryBsc0oQm+AStxlYVng==;EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "raw_container_client = blob_service_client.get_container_client(\"raw\")\n",
    "# Especificando o caminho do arquivo CSV no seu bucket\n",
    "blob_client = raw_container_client.get_blob_client(\"cobase-nfe2.xml\")\n",
    "\n",
    "# Lendo o arquivo CSV em um objeto pandas DataFrame\n",
    "#csv_data = blob_client.download_blob().content_as_text()\n",
    "xml = blob_client.download_blob()\n",
    "\n",
    "tree = ET.parse(xml)\n",
    "root = tree.getroot()\n",
    "\n",
    "#df = pd.read_csv(csv_data, sep=';')\n",
    "processing_container_name = blob_service_client.get_container_client(\"processing\")\n",
    "parquet_blob_client = blob_service_client.get_container_client(processing_container_name).get_blob_client('file.parquet')\n",
    "df.to_parquet(parquet_blob_client, partition_cols=['year', 'month', 'day'], index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando data lake azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>idade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marcos</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nome  idade\n",
       "0  marcos     33"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "\n",
    "# Configurando a conexão com o seu bucket na Azure\n",
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=t10storageaccount;AccountKey=+SRaplCEmzyqKRW+3j0jd79Qo6eganpiz+56yobjx5zAFwMuUk7eQeB9T/WfdutiI4VryBsc0oQm+AStxlYVng==;EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(\"landing\")\n",
    "\n",
    "# Especificando o caminho do arquivo CSV no seu bucket\n",
    "blob_client = container_client.get_blob_client(\"teste.csv\")\n",
    "\n",
    "# Lendo o arquivo CSV em um objeto pandas DataFrame\n",
    "#csv_data = blob_client.download_blob().content_as_text()\n",
    "csv_data = blob_client.download_blob()\n",
    "df = pd.read_csv(csv_data, sep=';')\n",
    "\n",
    "# Exibindo o DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'etag': '\"0x8DB2726CBDDFCCB\"',\n",
       " 'last_modified': datetime.datetime(2023, 3, 17, 20, 32, 58, tzinfo=datetime.timezone.utc),\n",
       " 'client_request_id': 'e5f6fcaf-c502-11ed-9c5a-20689d02b752',\n",
       " 'request_id': '13b6b111-401e-002e-7d0f-5980b8000000',\n",
       " 'version': '2021-12-02',\n",
       " 'version_id': None,\n",
       " 'date': datetime.datetime(2023, 3, 17, 20, 32, 58, tzinfo=datetime.timezone.utc),\n",
       " 'copy_id': 'af4dae8a-bf13-41cf-a8d6-40ddc940339a',\n",
       " 'copy_status': 'success'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movendo arquivo teste.csv da landing para RAW\n",
    "landing_container_client = blob_service_client.get_container_client(\"landing\")\n",
    "landing_blob_client = landing_container_client.get_blob_client(\"teste.csv\")\n",
    "\n",
    "raw_container_client = blob_service_client.get_container_client(\"raw\")\n",
    "raw_blob_client = raw_container_client.get_blob_client(\"teste.csv\")\n",
    "raw_blob_client.start_copy_from_url(landing_blob_client.url)\n",
    "\n",
    "\n",
    "#landing_blob_client.delete_blob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucesso!\n"
     ]
    }
   ],
   "source": [
    "data = raw_blob_client.get_blob_properties()\n",
    "status = raw_blob_client.get_blob_properties().copy.status\n",
    "\n",
    "if raw_blob_client.get_blob_properties().copy.status == 'success':\n",
    "    print(\"sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'teste.csv', 'container': 'raw', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2023, 3, 17, 20, 32, 58, tzinfo=datetime.timezone.utc), 'etag': '\"0x8DB2726CBDDFCCB\"', 'size': 21, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': 'af4dae8a-bf13-41cf-a8d6-40ddc940339a', 'source': 'https://t10storageaccount.blob.core.windows.net/landing/teste.csv', 'status': 'success', 'progress': '21/21', 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'text/csv', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'\\xa0\\xac\\xf1\\xb3\\tG\\xb5\\xc9 \\xa0Y.F\\xbfGC'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': False, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2023, 3, 17, 20, 32, 58, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': True, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 3, 17, 20, 32, 58, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modificacao = data['last_modified']\n",
    "data_modificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastparquet import *\n",
    "# LENDRO DA RAW E SALVANDO NA PROCESSING EM FORMATO PARQUET\n",
    "\n",
    "raw_container_client = blob_service_client.get_container_client(\"raw\")\n",
    "# Especificando o caminho do arquivo CSV no seu bucket\n",
    "raw_blob_client = raw_container_client.get_blob_client(\"teste.csv\")\n",
    "\n",
    "processing_container_client = blob_service_client.get_container_client(\"processing\")\n",
    "processing_blob_client = processing_container_client.get_blob_client(\"teste.parquet\")\n",
    "\n",
    "# Lendo o arquivo CSV em um objeto pandas DataFrame\n",
    "#csv_data = blob_client.download_blob().content_as_text()\n",
    "csv_data = raw_blob_client.download_blob()\n",
    "df = pd.read_csv(csv_data, sep=';')\n",
    "\n",
    "# Exibindo o DataFrame\n",
    "\n",
    "parquet_blob_data = df.to_parquet('teste.parquet',engine=\"fastparquet\")\n",
    "processing_blob_client.upload_blob(parquet_blob_data, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
